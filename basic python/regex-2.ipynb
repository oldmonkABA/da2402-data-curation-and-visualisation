{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Regular Expressions in Python\n",
    "\n",
    "Welcome to this advanced regex tutorial! This notebook will take you beyond basic pattern matching into the sophisticated world of advanced regular expressions. We'll cover:\n",
    "\n",
    "- **Lookahead and Lookbehind Assertions**\n",
    "- **Capturing Groups and Backreferences*\n",
    "- **Conditional Regex Patterns**\n",
    "- **Performance Optimization**\n",
    "- **Real-world Applications**\n",
    "\n",
    "### Prerequisites\n",
    "- Basic understanding of regular expressions\n",
    "- Python programming knowledge\n",
    "- Familiarity with the `re` module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import re\n",
    "import time\n",
    "import timeit\n",
    "from typing import List, Optional, Tuple\n",
    "import warnings\n",
    "\n",
    "# Helper function for testing regex patterns\n",
    "def test_regex(pattern: str, test_strings: List[str], flags: int = 0) -> None:\n",
    "    \"\"\"Test a regex pattern against multiple strings and display results.\"\"\"\n",
    "    compiled_pattern = re.compile(pattern, flags)\n",
    "    print(f\"Pattern: {pattern}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for test_string in test_strings:\n",
    "        match = compiled_pattern.search(test_string)\n",
    "        if match:\n",
    "            print(f\"✓ '{test_string}' -> Match: '{match.group()}'\")\n",
    "            if match.groups():\n",
    "                print(f\"  Groups: {match.groups()}\")\n",
    "        else:\n",
    "            print(f\"✗ '{test_string}' -> No match\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lookahead and Lookbehind Assertions\n",
    "\n",
    "Lookaround assertions allow you to match patterns based on what comes before or after, without including those parts in the match.\n",
    "\n",
    "### Types of Lookaround:\n",
    "- **Positive Lookahead** `(?=...)` - Matches if followed by pattern\n",
    "- **Negative Lookahead** `(?!...)` - Matches if NOT followed by pattern\n",
    "- **Positive Lookbehind** `(?<=...)` - Matches if preceded by pattern\n",
    "- **Negative Lookbehind** `(?<!...)` - Matches if NOT preceded by pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Part          | Type               | Matches / Purpose                                                    |\n",
    "| ------------- | ------------------ | -------------------------------------------------------------------- |\n",
    "| `^`           | Anchor             | Start of string                                                      |\n",
    "| `(?=.*\\d)`    | Positive lookahead | Ensures **at least one digit** (`0–9`) exists anywhere in the string |\n",
    "| `(?=.*[a-z])` | Positive lookahead | Ensures **at least one lowercase letter** exists anywhere            |\n",
    "| `(?=.*[A-Z])` | Positive lookahead | Ensures **at least one uppercase letter** exists anywhere            |\n",
    "| `.{8,}`       | Main match         | Matches **any 8 or more characters** (except newline)                |\n",
    "| `$`           | Anchor             | End of string                                                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password Validation with Positive Lookahead:\n",
      "Pattern: ^(?=.*\\d)(?=.*[a-z])(?=.*[A-Z]).{8,}$\n",
      "--------------------------------------------------\n",
      "✓ 'Password123' -> Match: 'Password123'\n",
      "✗ 'password123' -> No match\n",
      "✗ 'PASSWORD123' -> No match\n",
      "✗ 'Password' -> No match\n",
      "✗ 'Pass123' -> No match\n",
      "✓ 'MySecure1' -> Match: 'MySecure1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Positive Lookahead Example: Password Validation\n",
    "# Password must contain at least one digit, one lowercase, one uppercase, and be 8+ chars\n",
    "\n",
    "password_pattern = r'^(?=.*\\d)(?=.*[a-z])(?=.*[A-Z]).{8,}$'\n",
    "\n",
    "passwords = [\n",
    "    \"Password123\",    # Valid\n",
    "    \"password123\",    # No uppercase\n",
    "    \"PASSWORD123\",    # No lowercase\n",
    "    \"Password\",       # No digit\n",
    "    \"Pass123\",        # Too short\n",
    "    \"MySecure1\",      # Valid\n",
    "]\n",
    "\n",
    "print(\"Password Validation with Positive Lookahead:\")\n",
    "test_regex(password_pattern, passwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Part        | Type                   | Meaning / Purpose                                                |\n",
    "| ----------- | ---------------------- | ---------------------------------------------------------------- |\n",
    "| `file`      | Literal match          | Matches the exact characters `f`, `i`, `l`, `e`                  |\n",
    "| `(?!\\.txt)` | **Negative lookahead** | Asserts that what follows **is NOT `.txt`**                      |\n",
    "| `\\.`        | Escaped dot            | Matches a literal `.` (not \"any character\") inside the lookahead |\n",
    "| `txt`       | Literal match          | Matches `txt` inside the lookahead                               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Lookahead Example:\n",
      "Pattern: file(?=\\.txt)\n",
      "--------------------------------------------------\n",
      "✗ 'file.doc' -> No match\n",
      "✓ 'file.txt' -> Match: 'file'\n",
      "✗ 'filename.txt' -> No match\n",
      "✗ 'file system' -> No match\n",
      "✓ 'profile.txt' -> Match: 'file'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Negative Lookahead Example: Matching words not followed by specific patterns\n",
    "# Match 'file' but not when followed by '.txt'\n",
    "\n",
    "pattern = r'file(?!\\.txt)'\n",
    "\n",
    "test_strings = [\n",
    "    \"file.doc\",       # Match\n",
    "    \"file.txt\",       # No match\n",
    "    \"filename.txt\",   # Match 'file' part\n",
    "    \"file system\",    # Match\n",
    "    \"profile.txt\",    # Match 'file' part\n",
    "]\n",
    "\n",
    "print(\"Negative Lookahead Example:\")\n",
    "test_regex(pattern, test_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Part        | Type                    | Meaning / Purpose                                                       |\n",
    "| ----------- | ----------------------- | ----------------------------------------------------------------------- |\n",
    "| `(?<=[$₹])` | **Positive lookbehind** | Asserts that the match is **immediately preceded** by either `$` or `₹` |\n",
    "| `[$₹]`      | Character class         | Matches either a dollar sign (`$`) or rupee sign (`₹`)                  |\n",
    "| `\\d+`       | Quantifier              | Matches **one or more digits** — the whole number part of the price     |\n",
    "| `\\.`        | Escaped character       | Matches a **literal dot** (`.`) — separates rupees from paise/cents     |\n",
    "| `\\d{2}`     | Quantifier              | Matches **exactly two digits** — the decimal part (paise or cents)      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Lookbehind Example:\n",
      "Pattern: (?<=[$₹])\\d+\\.?(\\d{2})?\n",
      "--------------------------------------------------\n",
      "✓ '$19.99' -> Match: '19.99'\n",
      "  Groups: ('99',)\n",
      "✗ '€19.99' -> No match\n",
      "✓ 'Price: ₹45.00' -> Match: '45.00'\n",
      "  Groups: ('00',)\n",
      "✓ 'Amount: ₹25' -> Match: '25'\n",
      "  Groups: (None,)\n",
      "✗ '19.99 dollars' -> No match\n",
      "✓ 'Save $10.50!' -> Match: '10.50'\n",
      "  Groups: ('50',)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Positive Lookbehind Example: Currency amounts preceded by '$'\n",
    "pattern = r'(?<=[$₹])\\d+\\.\\d{2}'\n",
    "#pattern = r'(?<=[$₹])\\d+\\.?(\\d{2})?'\n",
    "test_strings = [\n",
    "    \"$19.99\",         # Match: 19.99\n",
    "    \"€19.99\",         # No match\n",
    "    \"Price: ₹45.00\",  # Match: 45.00\n",
    "    \"Amount: ₹25\",\n",
    "    \"19.99 dollars\",  # No match\n",
    "    \"Save $10.50!\",   # Match: 10.50\n",
    "]\n",
    "\n",
    "print(\"Positive Lookbehind Example:\")\n",
    "test_regex(pattern, test_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Part      | Type                    | Meaning / Purpose                                               |\n",
    "| --------- | ----------------------- | --------------------------------------------------------------- |\n",
    "| `(?<!\\$)` | **Negative lookbehind** | Asserts that the match is **not immediately preceded** by a `$` |\n",
    "| `\\d+`     | Quantifier              | Matches **one or more digits** — the whole number part          |\n",
    "| `\\.`      | Escaped character       | Matches a **literal dot** (`.`)                                 |\n",
    "| `\\d{2}`   | Quantifier              | Matches **exactly two digits** — the decimal part (e.g., `.99`) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Lookbehind Example:\n",
      "Pattern: (?<!\\$)\\d+\\.\\d{2}\n",
      "--------------------------------------------------\n",
      "✓ '$19.99' -> Match: '9.99'\n",
      "✓ '€19.99' -> Match: '19.99'\n",
      "✓ 'Temperature: 98.60' -> Match: '98.60'\n",
      "✓ 'Price $45.00' -> Match: '5.00'\n",
      "✓ 'Version 2.10' -> Match: '2.10'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Negative Lookbehind Example: Numbers not preceded by '$'\n",
    "pattern = r'(?<!\\$)\\d+\\.\\d{2}'\n",
    "#\\b\n",
    "test_strings = [\n",
    "    \"$19.99\",         # No match\n",
    "    \"€19.99\",         # Match: 19.99\n",
    "    \"Temperature: 98.60\", # Match: 98.60\n",
    "    \"Price $45.00\",   # No match\n",
    "    \"Version 2.10\",   # Match: 2.10\n",
    "]\n",
    "\n",
    "print(\"Negative Lookbehind Example:\")\n",
    "test_regex(pattern, test_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Email Validation with Lookaround\n",
    "\n",
    "Create a regex pattern that validates email addresses with these requirements:\n",
    "- Must contain exactly one '@' symbol\n",
    "- Domain must end with '.com', '.org', or '.edu'\n",
    "- Username cannot start or end with dots\n",
    "- No consecutive dots allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Part                | Type               | Meaning / Purpose                                         |                        |                                                                 |\n",
    "| ------------------- | ------------------ | --------------------------------------------------------- | ---------------------- | --------------------------------------------------------------- |\n",
    "| `^`                 | Anchor             | Start of the string                                       |                        |                                                                 |\n",
    "| `(?!\\.)`            | Negative lookahead | ❌ Disallow email starting with a dot                      |                        |                                                                 |\n",
    "| `(?!.*\\.\\.)`        | Negative lookahead | ❌ Disallow double dots anywhere in the email              |                        |                                                                 |\n",
    "| `(?!.*\\.$)`         | Negative lookahead | ❌ Disallow email ending with a dot                        |                        |                                                                 |\n",
    "| `[a-zA-Z0-9._%+-]+` | Character class    | ✅ Local part (username) — allowed characters before `@`   |                        |                                                                 |\n",
    "| `@`                 | Literal character  | Mandatory `@` symbol separating local and domain parts    |                        |                                                                 |\n",
    "| `[a-zA-Z0-9.-]+`    | Character class    | ✅ Domain name — allows letters, digits, dots, and hyphens |                        |                                                                 |\n",
    "| `\\.`                | Escaped dot        | Literal dot separating domain and TLD                     |                        |                                                                 |\n",
    "| \\`(com              | org                | edu)\\`                                                    | Group with alternation | ✅ Acceptable domain endings (TLDs): only `.com`, `.org`, `.edu` |\n",
    "| `$`                 | Anchor             | End of the string                                         |                        |                                                                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Validation Exercise:\n",
      "Pattern: ^(?!\\.)(?!.*\\.\\.)(?!.*\\.$)[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.(com|org|edu)$\n",
      "--------------------------------------------------\n",
      "✓ 'user@example.com' -> Match: 'user@example.com'\n",
      "  Groups: ('com',)\n",
      "✗ '.user@example.com' -> No match\n",
      "✓ 'user.@example.com' -> Match: 'user.@example.com'\n",
      "  Groups: ('com',)\n",
      "✗ 'us..er@example.com' -> No match\n",
      "✗ 'user@example.net' -> No match\n",
      "✓ 'valid.email@test.org' -> Match: 'valid.email@test.org'\n",
      "  Groups: ('org',)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1 Solution\n",
    "email_pattern = r'^(?!\\.)(?!.*\\.\\.)(?!.*\\.$)[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.(com|org|edu)$'\n",
    "\n",
    "emails = [\n",
    "    \"user@example.com\",      # Valid\n",
    "    \".user@example.com\",     # Invalid: starts with dot\n",
    "    \"user.@example.com\",     # Invalid: ends with dot\n",
    "    \"us..er@example.com\",    # Invalid: consecutive dots\n",
    "    \"user@example.net\",      # Invalid: wrong TLD\n",
    "    \"valid.email@test.org\",  # Valid\n",
    "]\n",
    "\n",
    "print(\"Email Validation Exercise:\")\n",
    "test_regex(email_pattern, emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Capturing Groups and Backreferences\n",
    "\n",
    "Capturing groups allow you to extract parts of your match and reference them later in the same pattern or in replacement strings.\n",
    "\n",
    "### Types of Groups:\n",
    "- **Capturing Group** `(...)` - Captures and numbers the group\n",
    "- **Named Group** `(?P<name>...)` - Captures with a name\n",
    "- **Non-capturing Group** `(?:...)` - Groups without capturing\n",
    "- **Backreference** `\\1, \\2` or `(?P=name)` - References captured groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Part               | Type                  | Meaning / Purpose                                  | Example Match |\n",
    "| ------------------ | --------------------- | -------------------------------------------------- | ------------- |\n",
    "| `(?P<year>\\d{4})`  | Named capturing group | Matches **4 digits** and stores as group `\"year\"`  | `2023`        |\n",
    "| `-`                | Literal character     | Matches a **hyphen** separator                     | `-`           |\n",
    "| `(?P<month>\\d{2})` | Named capturing group | Matches **2 digits** and stores as group `\"month\"` | `08`          |\n",
    "| `-`                | Literal character     | Matches another hyphen                             | `-`           |\n",
    "| `(?P<day>\\d{2})`   | Named capturing group | Matches **2 digits** and stores as group `\"day\"`   | `04`          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Groups Example:\n",
      "Date: 2023-12-25\n",
      "  Year: 2023\n",
      "  Month: 12\n",
      "  Day: 25\n",
      "  Full match: 2023-12-25\n",
      "\n",
      "Date: 2024-01-01\n",
      "  Year: 2024\n",
      "  Month: 01\n",
      "  Day: 01\n",
      "  Full match: 2024-01-01\n",
      "\n",
      "Date: 1999-07-15\n",
      "  Year: 1999\n",
      "  Month: 07\n",
      "  Day: 15\n",
      "  Full match: 1999-07-15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Named Capturing Groups Example: Parsing dates\n",
    "date_pattern = r'(?P<year>\\d{4})-(?P<month>\\d{2})-(?P<day>\\d{2})'\n",
    "\n",
    "dates = [\n",
    "    \"2023-12-25\",\n",
    "    \"2024-01-01\",\n",
    "    \"1999-07-15\",\n",
    "]\n",
    "\n",
    "print(\"Named Groups Example:\")\n",
    "compiled_pattern = re.compile(date_pattern)\n",
    "for date in dates:\n",
    "    match = compiled_pattern.search(date)\n",
    "    if match:\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"  Year: {match.group('year')}\")\n",
    "        print(f\"  Month: {match.group('month')}\")\n",
    "        print(f\"  Day: {match.group('day')}\")\n",
    "        print(f\"  Full match: {match.group()}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Part    | Meaning                                                                                |\n",
    "| ------- | -------------------------------------------------------------------------------------- |\n",
    "| `\\b`    | Word boundary — ensures the match starts at the **start of a word**                    |\n",
    "| `(\\w+)` | **Capturing group 1** — matches one or more word characters (`a-z`, `A-Z`, `0-9`, `_`) |\n",
    "| `\\s+`   | One or more whitespace characters (space, tab, newline)                                |\n",
    "| `\\1`    | **Backreference** — matches **the same exact word** captured in group 1                |\n",
    "| `\\b`    | Word boundary — ensures the match ends at the **end of the repeated word**             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Words with Backreferences:\n",
      "Pattern: \\b(\\w+)\\s+\\1\\b\n",
      "--------------------------------------------------\n",
      "✓ 'This is is a test' -> Match: 'is is'\n",
      "  Groups: ('is',)\n",
      "✓ 'The the quick brown fox' -> Match: 'The the'\n",
      "  Groups: ('The',)\n",
      "✗ 'No repeated words here' -> No match\n",
      "✓ 'Buffalo buffalo buffalo' -> Match: 'Buffalo buffalo'\n",
      "  Groups: ('Buffalo',)\n",
      "✓ 'Hello world world!' -> Match: 'world world'\n",
      "  Groups: ('world',)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Backreferences Example: Finding repeated words\n",
    "repeated_word_pattern = r'\\b(\\w+)\\s+\\1\\b'\n",
    "\n",
    "sentences = [\n",
    "    \"This is is a test\",           # Match: 'is is'\n",
    "    \"The the quick brown fox\",     # Match: 'The the'\n",
    "    \"No repeated words here\",      # No match\n",
    "    \"Buffalo buffalo buffalo\",     # Match: 'buffalo buffalo'\n",
    "    \"Hello world world!\",          # Match: 'world world'\n",
    "]\n",
    "\n",
    "print(\"Repeated Words with Backreferences:\")\n",
    "test_regex(repeated_word_pattern, sentences, re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML Tag Matching with Named Backreferences:\n",
      "Pattern: <(?P<tag>\\w+)>.*?</(?P=tag)>\n",
      "--------------------------------------------------\n",
      "✓ '<div>Content</div>' -> Match: '<div>Content</div>'\n",
      "  Groups: ('div',)\n",
      "✓ '<p>Paragraph</p>' -> Match: '<p>Paragraph</p>'\n",
      "  Groups: ('p',)\n",
      "✗ '<div>Content</span>' -> No match\n",
      "✓ '<h1>Title</h1>' -> Match: '<h1>Title</h1>'\n",
      "  Groups: ('h1',)\n",
      "✗ '<img src='test.jpg'>' -> No match\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Named Backreferences Example: Matching opening and closing HTML tags\n",
    "html_tag_pattern = r'<(?P<tag>\\w+)>.*?</(?P=tag)>'\n",
    "\n",
    "html_snippets = [\n",
    "    \"<div>Content</div>\",          # Match\n",
    "    \"<p>Paragraph</p>\",            # Match\n",
    "    \"<div>Content</span>\",         # No match\n",
    "    \"<h1>Title</h1>\",              # Match\n",
    "    \"<img src='test.jpg'>\",        # No match (self-closing)\n",
    "]\n",
    "\n",
    "print(\"HTML Tag Matching with Named Backreferences:\")\n",
    "test_regex(html_tag_pattern, html_snippets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Part       | Type                  | Meaning / Purpose                                             |                                                                                       |\n",
    "| ---------- | --------------------- | ------------------------------------------------------------- | ------------------------------------------------------------------------------------- |\n",
    "| \\`(?:^     | ,)\\`                  | Non-capturing group                                           | Matches either the **start of line (`^`)** or a **comma (`,`)** — field separator     |\n",
    "| `(`        | Capturing group start | Start capturing the actual field content                      |                                                                                       |\n",
    "| `\"(...)*\"` | Quoted field format   | Starts and ends with `\"` — indicates a **quoted field**       |                                                                                       |\n",
    "| \\`(?:\\[^\"] | \"\")\\*\\`               | Non-capturing inner group                                     | Matches zero or more of:<br> - `[^\"]`: any char except `\"`,<br> - `\"\"`: escaped quote |\n",
    "| \\`         | \\`                    | Alternation                                                   | OR — allows matching either quoted or unquoted field                                  |\n",
    "| `[^,]*`    | Unquoted field        | Match any characters that are **not commas** (unquoted field) |                                                                                       |\n",
    "| `)`        | Capturing group end   | End of field-capturing group                                  |                                                                                       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Parsing Example:\n",
      "Line: name,age,city\n",
      "Fields: ['name', 'age', 'city']\n",
      "\n",
      "Line: John,25,\"New York\"\n",
      "Fields: ['John', '25', 'New York']\n",
      "\n",
      "Line: \"Smith, Jane\",30,Boston\n",
      "Fields: ['Smith, Jane', '30', 'Boston']\n",
      "\n",
      "Line: Bob,35,\"Los Angeles, CA\"\n",
      "Fields: ['Bob', '35', 'Los Angeles, CA']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Advanced Example: Parsing CSV with quoted fields\n",
    "csv_pattern = r'(?:^|,)(\"(?:[^\"]|\"\")*\"|[^,]*)'\n",
    "\n",
    "csv_lines = [\n",
    "    'name,age,city',\n",
    "    'John,25,\"New York\"',\n",
    "    '\"Smith, Jane\",30,Boston',\n",
    "    'Bob,35,\"Los Angeles, CA\"',\n",
    "]\n",
    "\n",
    "print(\"CSV Parsing Example:\")\n",
    "for line in csv_lines:\n",
    "    matches = re.findall(csv_pattern, line)\n",
    "    fields = [field.strip('\"') for field in matches]\n",
    "    print(f\"Line: {line}\")\n",
    "    print(f\"Fields: {fields}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Palindrome Detection\n",
    "\n",
    "Create a regex pattern that detects palindromes (words that read the same forwards and backwards) using backreferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Part    | Type                     | Meaning / Role                                            |\n",
    "| ------- | ------------------------ | --------------------------------------------------------- |\n",
    "| `^`     | Anchor                   | Start of the string                                       |\n",
    "| `(\\w)`  | Capturing group 1        | First character (always required)                         |\n",
    "| `(\\w)?` | Capturing group 2        | Second character (optional)                               |\n",
    "| `(\\w)?` | Capturing group 3        | Third character (optional)                                |\n",
    "| `\\3?`   | Backreference (optional) | Match the **same character as group 3**, if present       |\n",
    "| `\\2?`   | Backreference (optional) | Match the **same character as group 2**, if present       |\n",
    "| `\\1`    | Backreference            | Match the **same character as group 1** (always required) |\n",
    "| `$`     | Anchor                   | End of the string                                         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palindrome Detection:\n",
      "'racecar' -> Palindrome\n",
      "'level' -> Palindrome\n",
      "'hello' -> Not a palindrome\n",
      "'madam' -> Palindrome\n",
      "'python' -> Not a palindrome\n",
      "'A man a plan a canal Panama' -> Palindrome\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2 Solution: Palindrome Detection\n",
    "# Note: This is a simplified version for short palindromes\n",
    "palindrome_pattern = r'^(\\w)(\\w)?(\\w)?\\3?\\2?\\1$'\n",
    "\n",
    "# For a more general solution, we'll use Python logic\n",
    "def is_palindrome_regex(word):\n",
    "    \"\"\"Check if a word is a palindrome using regex concepts.\"\"\"\n",
    "    # Remove non-alphanumeric and convert to lowercase\n",
    "    clean_word = re.sub(r'[^a-zA-Z0-9]', '', word.lower())\n",
    "    \n",
    "    # Create dynamic pattern for palindrome checking\n",
    "    length = len(clean_word)\n",
    "    if length <= 1:\n",
    "        return True\n",
    "    \n",
    "    # Build pattern dynamically\n",
    "    pattern_parts = []\n",
    "    for i in range(length // 2):\n",
    "        pattern_parts.append(f'(\\w)')\n",
    "    \n",
    "    if length % 2 == 1:\n",
    "        pattern_parts.append('\\w?')  # Middle character for odd length\n",
    "    \n",
    "    # Add backreferences in reverse order\n",
    "    for i in range(length // 2, 0, -1):\n",
    "        pattern_parts.append(f'\\\\{i}')\n",
    "    \n",
    "    pattern = '^' + ''.join(pattern_parts) + '$'\n",
    "    return bool(re.match(pattern, clean_word))\n",
    "\n",
    "test_words = [\n",
    "    \"racecar\",     # True\n",
    "    \"level\",       # True\n",
    "    \"hello\",       # False\n",
    "    \"madam\",       # True\n",
    "    \"python\",      # False\n",
    "    \"A man a plan a canal Panama\",  # True (ignoring spaces)\n",
    "]\n",
    "\n",
    "print(\"Palindrome Detection:\")\n",
    "for word in test_words:\n",
    "    result = is_palindrome_regex(word)\n",
    "    print(f\"'{word}' -> {'Palindrome' if result else 'Not a palindrome'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Atomic Groups and Possessive Quantifiers\n",
    "\n",
    "Atomic groups and possessive quantifiers help prevent catastrophic backtracking and improve performance.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Possessive Quantifiers** `*+, ++, ?+, {n,m}+` - Don't give up characters once matched\n",
    "- **Catastrophic Backtracking** - When regex engine tries too many combinations\n",
    "\n",
    "**Note:** Python's `re` module has limited support for atomic groups. We'll demonstrate the concepts and show alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstrating Backtracking Issues:\n",
      "Optimized pattern: 0.0000s - No match\n",
      "\n",
      "Note: The problematic pattern (a+)+b would take much longer on longer strings without 'b'\n",
      "This demonstrates why atomic groups and possessive quantifiers are important.\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating Catastrophic Backtracking\n",
    "import time\n",
    "\n",
    "def time_regex(pattern, text, description):\n",
    "    \"\"\"Time how long a regex takes to execute.\"\"\"\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        result = re.search(pattern, text)\n",
    "        end_time = time.time()\n",
    "        print(f\"{description}: {end_time - start_time:.4f}s - {'Match' if result else 'No match'}\")\n",
    "    except Exception as e:\n",
    "        end_time = time.time()\n",
    "        print(f\"{description}: {end_time - start_time:.4f}s - Error: {e}\")\n",
    "\n",
    "# Problematic pattern that can cause catastrophic backtracking\n",
    "problematic_pattern = r'(a+)+b'\n",
    "# Better pattern using non-capturing group\n",
    "better_pattern = r'a+b'\n",
    "\n",
    "# Test string that will cause backtracking (no 'b' at the end)\n",
    "test_string = 'a' * 20  # String of 20 'a's with no 'b'\n",
    "\n",
    "print(\"Demonstrating Backtracking Issues:\")\n",
    "time_regex(better_pattern, test_string, \"Optimized pattern\")\n",
    "print(\"\\nNote: The problematic pattern (a+)+b would take much longer on longer strings without 'b'\")\n",
    "print(\"This demonstrates why atomic groups and possessive quantifiers are important.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Comparison:\n",
      "Inefficient: 0.0006s (1000 matches)\n",
      "Better: 0.0011s (9000 matches)\n",
      "Compiled: 0.0012s (9000 matches)\n"
     ]
    }
   ],
   "source": [
    "# Performance Optimization Techniques\n",
    "\n",
    "def compare_regex_performance():\n",
    "    \"\"\"Compare different regex approaches for performance.\"\"\"\n",
    "    \n",
    "    # Test data\n",
    "    text = \"The quick brown fox jumps over the lazy dog. \" * 1000\n",
    "    \n",
    "    # Different approaches to find words\n",
    "    patterns = {\n",
    "        \"Inefficient\": r'(\\w+\\s*)+',  # Can cause backtracking\n",
    "        \"Better\": r'\\w+',             # Simple and efficient\n",
    "        \"Compiled\": re.compile(r'\\w+'),  # Pre-compiled\n",
    "    }\n",
    "    \n",
    "    print(\"Performance Comparison:\")\n",
    "    \n",
    "    for name, pattern in patterns.items():\n",
    "        if name == \"Compiled\":\n",
    "            # Time the compiled version\n",
    "            start_time = time.time()\n",
    "            matches = pattern.findall(text)\n",
    "            end_time = time.time()\n",
    "        else:\n",
    "            # Time the regular version\n",
    "            start_time = time.time()\n",
    "            matches = re.findall(pattern, text)\n",
    "            end_time = time.time()\n",
    "        \n",
    "        print(f\"{name}: {end_time - start_time:.4f}s ({len(matches)} matches)\")\n",
    "\n",
    "compare_regex_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conditional Regex Patterns\n",
    "\n",
    "Conditional patterns allow you to match different alternatives based on whether a previous group matched.\n",
    "\n",
    "**Syntax:** `(?(condition)yes-pattern|no-pattern)`\n",
    "\n",
    "**Note:** Python's `re` module has limited support for conditionals. We'll show the concept and Python alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flexible Date Matching:\n",
      "'2023-12-25' -> ISO format (YYYY-MM-DD)\n",
      "  Groups: ('2023', '12', '25')\n",
      "\n",
      "'12/25/2023' -> US format (MM/DD/YYYY)\n",
      "  Groups: ('12', '25', '2023')\n",
      "\n",
      "'25.12.2023' -> European format (DD.MM.YYYY)\n",
      "  Groups: ('25', '12', '2023')\n",
      "\n",
      "'December 25, 2023' -> Long format (Month DD, YYYY)\n",
      "  Groups: ('December', '25', '2023')\n",
      "\n",
      "'Invalid date format' -> No match found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simulating Conditional Regex in Python\n",
    "\n",
    "def flexible_date_matcher(date_string):\n",
    "    \"\"\"Match dates in multiple formats using conditional logic.\"\"\"\n",
    "    \n",
    "    # Different date patterns\n",
    "    patterns = [\n",
    "        (r'(\\d{4})-(\\d{2})-(\\d{2})', 'ISO format (YYYY-MM-DD)'),\n",
    "        (r'(\\d{2})/(\\d{2})/(\\d{4})', 'US format (MM/DD/YYYY)'),\n",
    "        (r'(\\d{2})\\.(\\d{2})\\.(\\d{4})', 'European format (DD.MM.YYYY)'),\n",
    "        (r'(\\w+)\\s+(\\d{1,2}),\\s+(\\d{4})', 'Long format (Month DD, YYYY)'),\n",
    "    ]\n",
    "    \n",
    "    for pattern, description in patterns:\n",
    "        match = re.search(pattern, date_string)\n",
    "        if match:\n",
    "            return {\n",
    "                'format': description,\n",
    "                'groups': match.groups(),\n",
    "                'full_match': match.group()\n",
    "            }\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Test different date formats\n",
    "test_dates = [\n",
    "    \"2023-12-25\",\n",
    "    \"12/25/2023\",\n",
    "    \"25.12.2023\",\n",
    "    \"December 25, 2023\",\n",
    "    \"Invalid date format\",\n",
    "]\n",
    "\n",
    "print(\"Flexible Date Matching:\")\n",
    "for date in test_dates:\n",
    "    result = flexible_date_matcher(date)\n",
    "    if result:\n",
    "        print(f\"'{date}' -> {result['format']}\")\n",
    "        print(f\"  Groups: {result['groups']}\")\n",
    "    else:\n",
    "        print(f\"'{date}' -> No match found\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Quantifiers and Unicode Support\n",
    "\n",
    "Understanding the nuances of quantifiers and working with Unicode text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Pattern | Behavior          | Example Match                                                   |\n",
    "| ------- | ----------------- | --------------------------------------------------------------- |\n",
    "| `.*`    | Greedy            | Eats everything up to last match                                |\n",
    "| `.*?`   | Non-greedy / lazy | Stops at the first match that satisfies the rest of the pattern |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantifier Comparison:\n",
      "Text: <div>First</div><div>Second</div><div>Third</div>\n",
      "\n",
      "Greedy (<div>.*</div>):\n",
      "  Match 1: <div>First</div><div>Second</div><div>Third</div>\n",
      "\n",
      "Lazy (<div>.*?</div>):\n",
      "  Match 1: <div>First</div>\n",
      "  Match 2: <div>Second</div>\n",
      "  Match 3: <div>Third</div>\n",
      "\n",
      "Specific (<div>[^<]*</div>):\n",
      "  Match 1: <div>First</div>\n",
      "  Match 2: <div>Second</div>\n",
      "  Match 3: <div>Third</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lazy vs Greedy Quantifiers\n",
    "\n",
    "def demonstrate_quantifiers():\n",
    "    \"\"\"Show the difference between greedy and lazy quantifiers.\"\"\"\n",
    "    \n",
    "    text = \"<div>First</div><div>Second</div><div>Third</div>\"\n",
    "    \n",
    "    patterns = {\n",
    "        \"Greedy\": r'<div>.*</div>',      # Matches from first <div> to last </div>\n",
    "        \"Lazy\": r'<div>.*?</div>',       # Matches each <div>...</div> separately\n",
    "        \"Specific\": r'<div>[^<]*</div>', # More specific, avoids the issue\n",
    "    }\n",
    "    \n",
    "    print(\"Quantifier Comparison:\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print()\n",
    "    \n",
    "    for name, pattern in patterns.items():\n",
    "        matches = re.findall(pattern, text)\n",
    "        print(f\"{name} ({pattern}):\")\n",
    "        for i, match in enumerate(matches, 1):\n",
    "            print(f\"  Match {i}: {match}\")\n",
    "        print()\n",
    "\n",
    "demonstrate_quantifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unicode Text Processing:\n",
      "\n",
      "Text: Hello World! 123\n",
      "  ASCII letters: ['Hello', 'World']\n",
      "  Word characters: ['Hello', 'World', '123']\n",
      "  Non-ASCII: []\n",
      "\n",
      "Text: Hola Mundo! 123\n",
      "  ASCII letters: ['Hola', 'Mundo']\n",
      "  Word characters: ['Hola', 'Mundo', '123']\n",
      "  Non-ASCII: []\n",
      "\n",
      "Text: Bonjour le monde! 123\n",
      "  ASCII letters: ['Bonjour', 'le', 'monde']\n",
      "  Word characters: ['Bonjour', 'le', 'monde', '123']\n",
      "  Non-ASCII: []\n",
      "\n",
      "Text: Привет नमस्ते ! 123\n",
      "  ASCII letters: []\n",
      "  Word characters: ['Привет', 'नमस', 'त', '123']\n",
      "  Non-ASCII: ['Привет', 'नमस्ते']\n",
      "\n",
      "Text: こんにちは世界！123\n",
      "  ASCII letters: []\n",
      "  Word characters: ['こんにちは世界', '123']\n",
      "  Non-ASCII: ['こんにちは世界！']\n",
      "\n",
      "Text: مرحبا بالعالم! 123\n",
      "  ASCII letters: []\n",
      "  Word characters: ['مرحبا', 'بالعالم', '123']\n",
      "  Non-ASCII: ['مرحبا', 'بالعالم']\n"
     ]
    }
   ],
   "source": [
    "# Unicode and International Text Processing\n",
    "\n",
    "def unicode_text_processing():\n",
    "    \"\"\"Demonstrate regex with Unicode text.\"\"\"\n",
    "    \n",
    "    # Sample text in different languages\n",
    "    texts = [\n",
    "        \"Hello World! 123\",           # English\n",
    "        \"Hola Mundo! 123\",            # Spanish\n",
    "        \"Bonjour le monde! 123\",      # French\n",
    "        \"Привет नमस्ते ! 123\",            # Russian\n",
    "        \"こんにちは世界！123\",            # Japanese\n",
    "        \"مرحبا بالعالم! 123\",          # Arabic\n",
    "    ]\n",
    "    \n",
    "    patterns = {\n",
    "        \"ASCII letters\": r'[a-zA-Z]+',\n",
    "        \n",
    "        \"Word characters\": r'\\w+',\n",
    "        \"Non-ASCII\": r'[^\\x00-\\x7F]+',\n",
    "    }\n",
    "    \n",
    "    print(\"Unicode Text Processing:\")\n",
    "    \n",
    "    for text in texts:\n",
    "        print(f\"\\nText: {text}\")\n",
    "        \n",
    "        # ASCII letters\n",
    "        ascii_matches = re.findall(r'[a-zA-Z]+', text)\n",
    "        print(f\"  ASCII letters: {ascii_matches}\")\n",
    "        \n",
    "        # Word characters (includes Unicode in Python)\n",
    "        word_matches = re.findall(r'\\w+', text, re.UNICODE)\n",
    "        print(f\"  Word characters: {word_matches}\")\n",
    "        \n",
    "        # Non-ASCII characters\n",
    "        non_ascii = re.findall(r'[^\\x00-\\x7F]+', text)\n",
    "        print(f\"  Non-ASCII: {non_ascii}\")\n",
    "\n",
    "unicode_text_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Boundary Examples:\n",
      "\n",
      "Text: 'The cat in the hat'\n",
      "  Words: ['The', 'cat', 'in', 'the', 'hat']\n",
      "  Contains 'cat' as whole word: Yes\n",
      "\n",
      "Text: 'email@example.com'\n",
      "  Words: ['email', 'example', 'com']\n",
      "  Contains 'cat' as whole word: No\n",
      "\n",
      "Text: 'file_name.txt'\n",
      "  Words: ['file_name', 'txt']\n",
      "  Contains 'cat' as whole word: No\n",
      "\n",
      "Text: 'hello-world'\n",
      "  Words: ['hello', 'world']\n",
      "  Contains 'cat' as whole word: No\n",
      "\n",
      "Text: 'café résumé naïve'\n",
      "  Words: ['café', 'résumé', 'naïve']\n",
      "  Contains 'cat' as whole word: No\n"
     ]
    }
   ],
   "source": [
    "# Word Boundaries with Unicode\n",
    "\n",
    "def word_boundary_examples():\n",
    "    \"\"\"Demonstrate word boundaries with different types of text.\"\"\"\n",
    "    \n",
    "    texts = [\n",
    "        \"The cat in the hat\",\n",
    "        \"email@example.com\",\n",
    "        \"file_name.txt\",\n",
    "        \"hello-world\",\n",
    "        \"café résumé naïve\",  # Accented characters\n",
    "    ]\n",
    "    \n",
    "    patterns = {\n",
    "        \"Word boundary \\\\b\": r'\\bcat\\b',\n",
    "        \"Non-word boundary \\\\B\": r'\\Bcat\\B',\n",
    "        \"Start of word\": r'\\b\\w+',\n",
    "        \"End of word\": r'\\w+\\b',\n",
    "    }\n",
    "    \n",
    "    print(\"Word Boundary Examples:\")\n",
    "    \n",
    "    for text in texts:\n",
    "        print(f\"\\nText: '{text}'\")\n",
    "        \n",
    "        # Find all word boundaries\n",
    "        words = re.findall(r'\\b\\w+\\b', text)\n",
    "        print(f\"  Words: {words}\")\n",
    "        \n",
    "        # Check if 'cat' appears as a whole word\n",
    "        if re.search(r'\\bcat\\b', text):\n",
    "            print(f\"  Contains 'cat' as whole word: Yes\")\n",
    "        else:\n",
    "            print(f\"  Contains 'cat' as whole word: No\")\n",
    "\n",
    "word_boundary_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Real-World Applications\n",
    "\n",
    "Let's apply our advanced regex knowledge to solve real-world problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Regex Part              | Name (`?P<name>`) | Matches Example Value        | Description                                 |\n",
    "| ----------------------- | ----------------- | ---------------------------- | ------------------------------------------- |\n",
    "| `^`                     | —                 | —                            | Start of the line                           |\n",
    "| `(?P<ip>\\S+)`           | `ip`              | `127.0.0.1`                  | Matches the **IP address** (non-whitespace) |\n",
    "| `\\S+`                   | —                 | `-`                          | Typically unused field (e.g., identity)     |\n",
    "| `(?P<user>\\S+)`         | `user`            | `frank`                      | Authenticated username or `-`               |\n",
    "| `\\[`                    | —                 | `[`                          | Literal opening square bracket              |\n",
    "| `(?P<timestamp>[^\\]]+)` | `timestamp`       | `10/Oct/2000:13:55:36 -0700` | Anything inside square brackets (`[ ... ]`) |\n",
    "| `\\]`                    | —                 | `]`                          | Literal closing square bracket              |\n",
    "| `\"`                     | —                 | `\"`                          | Opening double quote for HTTP request       |\n",
    "| `(?P<method>\\w+)`       | `method`          | `GET`                        | HTTP method (e.g., GET, POST)               |\n",
    "| `(?P<url>\\S+)`          | `url`             | `/apache_pb.gif`             | Request URL path                            |\n",
    "| `(?P<protocol>[^\"]+)`   | `protocol`        | `HTTP/1.0`                   | Protocol version, anything up to next `\"`   |\n",
    "| `\"`                     | —                 | `\"`                          | Closing double quote                        |\n",
    "| `(?P<status>\\d+)`       | `status`          | `200`                        | HTTP status code                            |\n",
    "| `(?P<size>\\d+)`         | `size`            | `2326`                       | Size of response in bytes                   |\n",
    "| `$`                     | —                 | —                            | End of the line                             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log File Parsing:\n",
      "IP: 192.168.1.1\n",
      "User: -\n",
      "Method: GET\n",
      "URL: /index.html\n",
      "Status: 200\n",
      "Size: 1234 bytes\n",
      "----------------------------------------\n",
      "IP: 10.0.0.1\n",
      "User: user\n",
      "Method: POST\n",
      "URL: /api/login\n",
      "Status: 401\n",
      "Size: 567 bytes\n",
      "----------------------------------------\n",
      "IP: 203.0.113.1\n",
      "User: -\n",
      "Method: GET\n",
      "URL: /images/logo.png\n",
      "Status: 404\n",
      "Size: 0 bytes\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Log File Parsing\n",
    "\n",
    "def parse_log_files():\n",
    "    \"\"\"Parse common log file formats.\"\"\"\n",
    "    \n",
    "    # Sample log entries\n",
    "    log_entries = [\n",
    "        '192.168.1.1 - - [25/Dec/2023:10:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 1234',\n",
    "        '10.0.0.1 - user [25/Dec/2023:10:01:00 +0000] \"POST /api/login HTTP/1.1\" 401 567',\n",
    "        '203.0.113.1 - - [25/Dec/2023:10:02:00 +0000] \"GET /images/logo.png HTTP/1.1\" 404 0',\n",
    "    ]\n",
    "    \n",
    "    # Apache Common Log Format pattern\n",
    "    log_pattern = r'^(?P<ip>\\S+) \\S+ (?P<user>\\S+) \\[(?P<timestamp>[^\\]]+)\\] \"(?P<method>\\w+) (?P<url>\\S+) (?P<protocol>[^\"]+)\" (?P<status>\\d+) (?P<size>\\d+)$'\n",
    "    \n",
    "    print(\"Log File Parsing:\")\n",
    "    compiled_pattern = re.compile(log_pattern)\n",
    "    \n",
    "    for entry in log_entries:\n",
    "        match = compiled_pattern.match(entry)\n",
    "        if match:\n",
    "            data = match.groupdict()\n",
    "            print(f\"IP: {data['ip']}\")\n",
    "            print(f\"User: {data['user']}\")\n",
    "            print(f\"Method: {data['method']}\")\n",
    "            print(f\"URL: {data['url']}\")\n",
    "            print(f\"Status: {data['status']}\")\n",
    "            print(f\"Size: {data['size']} bytes\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "parse_log_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contact Information Extraction:\n",
      "Text: Contact John Smith at john.smith@company.com or call (555) 123-4567.\n",
      "    You can also reach Jane Doe via jane.doe@example.org or +1-800-555-0199.\n",
      "    For urgent matters, contact support@help.com or dial 1-888-HELP-NOW.\n",
      "    Visit our office at 123 Main Street, Suite 456, New York, NY 10001.\n",
      "\n",
      "Extracted Information:\n",
      "\n",
      "Emails:\n",
      "  - john.smith@company.com\n",
      "  - jane.doe@example.org\n",
      "  - support@help.com\n",
      "\n",
      "Phones:\n",
      "  - (800) 555-0199\n",
      "\n",
      "Names:\n",
      "  - Contact John\n",
      "  - Jane Doe\n",
      "  - Main Street\n",
      "  - New York\n",
      "\n",
      "Addresses:\n",
      "  None found\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction from Unstructured Text\n",
    "\n",
    "def extract_contact_info():\n",
    "    \"\"\"Extract contact information from unstructured text.\"\"\"\n",
    "    \n",
    "    text = \"\"\"\n",
    "    Contact John Smith at john.smith@company.com or call (555) 123-4567.\n",
    "    You can also reach Jane Doe via jane.doe@example.org or +1-800-555-0199.\n",
    "    For urgent matters, contact support@help.com or dial 1-888-HELP-NOW.\n",
    "    Visit our office at 123 Main Street, Suite 456, New York, NY 10001.\n",
    "    \"\"\"\n",
    "    \n",
    "    patterns = {\n",
    "        'emails': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
    "        'phones': r'(?:\\+?1[-.]?)?\\(?([0-9]{3})\\)?[-.]?([0-9]{3})[-.]?([0-9]{4})',\n",
    "        'names': r'\\b[A-Z][a-z]+ [A-Z][a-z]+\\b',\n",
    "        'addresses': r'\\d+\\s+[A-Za-z\\s,]+\\s+[A-Z]{2}\\s+\\d{5}',\n",
    "    }\n",
    "    \n",
    "    print(\"Contact Information Extraction:\")\n",
    "    print(f\"Text: {text.strip()}\")\n",
    "    print(\"\\nExtracted Information:\")\n",
    "    \n",
    "    for info_type, pattern in patterns.items():\n",
    "        matches = re.findall(pattern, text)\n",
    "        print(f\"\\n{info_type.title()}:\")\n",
    "        if matches:\n",
    "            for match in matches:\n",
    "                if isinstance(match, tuple):\n",
    "                    # For phone numbers with groups\n",
    "                    formatted = f\"({match[0]}) {match[1]}-{match[2]}\"\n",
    "                    print(f\"  - {formatted}\")\n",
    "                else:\n",
    "                    print(f\"  - {match}\")\n",
    "        else:\n",
    "            print(\"  None found\")\n",
    "\n",
    "extract_contact_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Part                                  | Group Name | Type                 | Matches / Captures                                               |\n",
    "| ------------------------------------- | ---------- | -------------------- | ---------------------------------------------------------------- |\n",
    "| `^`                                   | —          | Anchor               | Start of the string                                              |\n",
    "| `(?P<scheme>[a-zA-Z][a-zA-Z0-9+.-]*)` | `scheme`   | Named group          | URL scheme (e.g., `http`, `ftp`, `https`, `mailto`)              |\n",
    "| `://`                                 | —          | Literal              | Required scheme separator                                        |\n",
    "| `(?:...)`                             | —          | Non-capturing group  | For wrapping optional username/password logic                    |\n",
    "| `(?P<username>[^:@]+)`                | `username` | Named group          | Username before `@`, can't include `:` or `@`                    |\n",
    "| `(?::(?P<password>[^@]+))?`           | `password` | Optional named group | Password after `:` (if present), can't include `@`               |\n",
    "| `@`                                   | —          | Literal              | Ends credentials section                                         |\n",
    "| `)?`                                  | —          | Optional wrapper     | Makes entire username\\:password@ section optional                |\n",
    "| `(?P<host>[^:/?#]+)`                  | `host`     | Named group          | Host (domain or IP) — can't include port `:`, path `/`, `?`, `#` |\n",
    "| `(?::(?P<port>\\d+))?`                 | `port`     | Optional named group | Port number, preceded by `:`                                     |\n",
    "| `(?P<path>/[^?#]*)?`                  | `path`     | Optional named group | Path, must start with `/`, excludes query and fragment           |\n",
    "| `(?:\\?(?P<query>[^#]*))?`             | `query`    | Optional named group | Query string, starts with `?`, excludes fragment (`#`)           |\n",
    "| `(?:\\#(?P<fragment>.*))?`             | `fragment` | Optional named group | Fragment identifier, starts with `#`, captures rest              |\n",
    "| `$`                                   | —          | Anchor               | End of the string                                                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced URL Parsing:\n",
      "\n",
      "URL: https://www.example.com:8080/path/to/page?param1=value1&param2=value2#section\n",
      "  Components:\n",
      "    scheme: https\n",
      "    host: www.example.com\n",
      "    port: 8080\n",
      "    path: /path/to/page\n",
      "    query: param1=value1&param2=value2\n",
      "    fragment: section\n",
      "\n",
      "URL: http://subdomain.example.org/api/v1/users/123\n",
      "  Components:\n",
      "    scheme: http\n",
      "    host: subdomain.example.org\n",
      "    path: /api/v1/users/123\n",
      "\n",
      "URL: ftp://user:pass@ftp.example.com:21/files/document.pdf\n",
      "  Components:\n",
      "    scheme: ftp\n",
      "    username: user\n",
      "    password: pass\n",
      "    host: ftp.example.com\n",
      "    port: 21\n",
      "    path: /files/document.pdf\n",
      "\n",
      "URL: mailto:user@example.com\n",
      "  Invalid URL format\n",
      "\n",
      "URL: invalid-url\n",
      "  Invalid URL format\n"
     ]
    }
   ],
   "source": [
    "# URL Validation and Parsing\n",
    "\n",
    "def advanced_url_parsing():\n",
    "    \"\"\"Parse and validate URLs with detailed component extraction.\"\"\"\n",
    "    \n",
    "    urls = [\n",
    "        \"https://www.example.com:8080/path/to/page?param1=value1&param2=value2#section\",\n",
    "        \"http://subdomain.example.org/api/v1/users/123\",\n",
    "        \"ftp://user:pass@ftp.example.com:21/files/document.pdf\",\n",
    "        \"mailto:user@example.com\",\n",
    "        \"invalid-url\",\n",
    "    ]\n",
    "    \n",
    "    # Comprehensive URL pattern\n",
    "    url_pattern = r'''\n",
    "        ^(?P<scheme>[a-zA-Z][a-zA-Z0-9+.-]*):// # Scheme\n",
    "        (?:\n",
    "            (?P<username>[^:@]+)                 # Username (optional)\n",
    "            (?::(?P<password>[^@]+))?            # Password (optional)\n",
    "            @\n",
    "        )?\n",
    "        (?P<host>[^:/?#]+)                       # Host\n",
    "        (?::(?P<port>\\d+))?                      # Port (optional)\n",
    "        (?P<path>/[^?#]*)?                       # Path (optional)\n",
    "        (?:\\?(?P<query>[^#]*))?                  # Query string (optional)\n",
    "        (?:\\#(?P<fragment>.*))?                  # Fragment (optional)\n",
    "        $\n",
    "    '''\n",
    "    \n",
    "    compiled_pattern = re.compile(url_pattern, re.VERBOSE)\n",
    "    \n",
    "    print(\"Advanced URL Parsing:\")\n",
    "    \n",
    "    for url in urls:\n",
    "        print(f\"\\nURL: {url}\")\n",
    "        match = compiled_pattern.match(url)\n",
    "        \n",
    "        if match:\n",
    "            components = match.groupdict()\n",
    "            print(\"  Components:\")\n",
    "            for key, value in components.items():\n",
    "                if value:\n",
    "                    print(f\"    {key}: {value}\")\n",
    "        else:\n",
    "            print(\"  Invalid URL format\")\n",
    "\n",
    "advanced_url_parsing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Optimization and Best Practices\n",
    "\n",
    "Learn how to write efficient regex patterns and avoid common pitfalls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex Compilation Benchmark:\n",
      "No caching: 0.5775s\n",
      "Pre-compiled: 0.5556s\n",
      "With caching: 0.5574s\n",
      "Speedup (compiled vs no cache): 1.04x\n"
     ]
    }
   ],
   "source": [
    "# Regex Compilation and Caching\n",
    "\n",
    "import functools\n",
    "\n",
    "class RegexCache:\n",
    "    \"\"\"A simple regex compilation cache.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size=100):\n",
    "        self.cache = {}\n",
    "        self.max_size = max_size\n",
    "    \n",
    "    def get_compiled_regex(self, pattern, flags=0):\n",
    "        \"\"\"Get a compiled regex, using cache when possible.\"\"\"\n",
    "        key = (pattern, flags)\n",
    "        \n",
    "        if key not in self.cache:\n",
    "            if len(self.cache) >= self.max_size:\n",
    "                # Remove oldest entry (simple FIFO)\n",
    "                oldest_key = next(iter(self.cache))\n",
    "                del self.cache[oldest_key]\n",
    "            \n",
    "            self.cache[key] = re.compile(pattern, flags)\n",
    "        \n",
    "        return self.cache[key]\n",
    "\n",
    "# Global regex cache instance\n",
    "regex_cache = RegexCache()\n",
    "\n",
    "def benchmark_compilation():\n",
    "    \"\"\"Benchmark regex compilation vs caching.\"\"\"\n",
    "    \n",
    "    pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    text = \"Contact us at support@example.com or sales@company.org\" * 1000\n",
    "    iterations = 1000\n",
    "    \n",
    "    # Test without caching (compile each time)\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        re.findall(pattern, text)\n",
    "    no_cache_time = time.time() - start_time\n",
    "    \n",
    "    # Test with pre-compilation\n",
    "    compiled_pattern = re.compile(pattern)\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        compiled_pattern.findall(text)\n",
    "    compiled_time = time.time() - start_time\n",
    "    \n",
    "    # Test with caching\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        cached_pattern = regex_cache.get_compiled_regex(pattern)\n",
    "        cached_pattern.findall(text)\n",
    "    cached_time = time.time() - start_time\n",
    "    \n",
    "    print(\"Regex Compilation Benchmark:\")\n",
    "    print(f\"No caching: {no_cache_time:.4f}s\")\n",
    "    print(f\"Pre-compiled: {compiled_time:.4f}s\")\n",
    "    print(f\"With caching: {cached_time:.4f}s\")\n",
    "    print(f\"Speedup (compiled vs no cache): {no_cache_time/compiled_time:.2f}x\")\n",
    "\n",
    "benchmark_compilation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Pitfalls Demonstration:\n",
      "Better alternative: 0.000030s - Match\n",
      "Optimized alternation: 0.000003s - No match\n",
      "\n",
      "Note: Avoided testing catastrophic patterns to prevent long execution times.\n",
      "\n",
      "Alternation Optimization:\n",
      "'cat': Inefficient=Match, Optimized=Match\n",
      "'category': Inefficient=Match, Optimized=Match\n",
      "'catastrophe': Inefficient=Match, Optimized=Match\n",
      "'dog': Inefficient=No match, Optimized=No match\n"
     ]
    }
   ],
   "source": [
    "# Common Performance Pitfalls and Solutions\n",
    "\n",
    "def demonstrate_performance_pitfalls():\n",
    "    \"\"\"Show common regex performance issues and their solutions.\"\"\"\n",
    "    \n",
    "    test_text = \"a\" * 1000 + \"b\"  # 1000 'a's followed by 'b'\n",
    "    \n",
    "    patterns = {\n",
    "        \"Catastrophic (avoid)\": r'(a+)+b',\n",
    "        \"Better alternative\": r'a+b',\n",
    "        \"Inefficient alternation\": r'(cat|category|catastrophe)',\n",
    "        \"Optimized alternation\": r'cat(egory|astrophe)?',\n",
    "    }\n",
    "    \n",
    "    print(\"Performance Pitfalls Demonstration:\")\n",
    "    \n",
    "    # Safe patterns to test\n",
    "    safe_patterns = {\n",
    "        \"Better alternative\": r'a+b',\n",
    "        \"Optimized alternation\": r'cat(egory|astrophe)?',\n",
    "    }\n",
    "    \n",
    "    for name, pattern in safe_patterns.items():\n",
    "        start_time = time.time()\n",
    "        result = re.search(pattern, test_text)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"{name}: {end_time - start_time:.6f}s - {'Match' if result else 'No match'}\")\n",
    "    \n",
    "    print(\"\\nNote: Avoided testing catastrophic patterns to prevent long execution times.\")\n",
    "    \n",
    "    # Demonstrate alternation optimization\n",
    "    test_words = [\"cat\", \"category\", \"catastrophe\", \"dog\"]\n",
    "    \n",
    "    print(\"\\nAlternation Optimization:\")\n",
    "    for word in test_words:\n",
    "        match1 = re.search(r'(cat|category|catastrophe)', word)\n",
    "        match2 = re.search(r'cat(egory|astrophe)?', word)\n",
    "        \n",
    "        result1 = \"Match\" if match1 else \"No match\"\n",
    "        result2 = \"Match\" if match2 else \"No match\"\n",
    "        \n",
    "        print(f\"'{word}': Inefficient={result1}, Optimized={result2}\")\n",
    "\n",
    "demonstrate_performance_pitfalls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Debugging and Testing Regex\n",
    "\n",
    "Tools and techniques for debugging complex regex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging Regex: URL parsing with named groups\n",
      "Pattern: (?P<protocol>https?)://(?P<domain>[^/]+)(?P<path>/.*)?\n",
      "Text: Visit https://www.example.com/path/to/page\n",
      "--------------------------------------------------\n",
      "Found 1 match(es):\n",
      "\n",
      "Match 1:\n",
      "  Full match: 'https://www.example.com/path/to/page'\n",
      "  Position: 6-42\n",
      "  Groups: ('https', 'www.example.com', '/path/to/page')\n",
      "  Named groups: {'protocol': 'https', 'domain': 'www.example.com', 'path': '/path/to/page'}\n",
      "\n",
      "Pattern Analysis:\n",
      "  Groups in pattern: 3\n",
      "  Named groups: {'protocol': 1, 'domain': 2, 'path': 3}\n",
      "============================================================\n",
      "Debugging Regex: Date extraction with numbered groups\n",
      "Pattern: (\\d{2})/(\\d{2})/(\\d{4})\n",
      "Text: Today is 12/25/2023 and tomorrow is 12/26/2023\n",
      "--------------------------------------------------\n",
      "Found 2 match(es):\n",
      "\n",
      "Match 1:\n",
      "  Full match: '12/25/2023'\n",
      "  Position: 9-19\n",
      "  Groups: ('12', '25', '2023')\n",
      "\n",
      "Match 2:\n",
      "  Full match: '12/26/2023'\n",
      "  Position: 36-46\n",
      "  Groups: ('12', '26', '2023')\n",
      "\n",
      "Pattern Analysis:\n",
      "  Groups in pattern: 3\n",
      "  Named groups: {}\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Regex Debugging Tools\n",
    "\n",
    "def debug_regex(pattern, text, description=\"\"):\n",
    "    \"\"\"Debug a regex pattern with detailed information.\"\"\"\n",
    "    \n",
    "    print(f\"Debugging Regex: {description}\")\n",
    "    print(f\"Pattern: {pattern}\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        compiled_pattern = re.compile(pattern)\n",
    "        \n",
    "        # Find all matches\n",
    "        matches = list(compiled_pattern.finditer(text))\n",
    "        \n",
    "        if matches:\n",
    "            print(f\"Found {len(matches)} match(es):\")\n",
    "            for i, match in enumerate(matches, 1):\n",
    "                print(f\"\\nMatch {i}:\")\n",
    "                print(f\"  Full match: '{match.group()}'\")\n",
    "                print(f\"  Position: {match.start()}-{match.end()}\")\n",
    "                \n",
    "                if match.groups():\n",
    "                    print(f\"  Groups: {match.groups()}\")\n",
    "                \n",
    "                if hasattr(match, 'groupdict') and match.groupdict():\n",
    "                    print(f\"  Named groups: {match.groupdict()}\")\n",
    "        else:\n",
    "            print(\"No matches found\")\n",
    "            \n",
    "        # Show pattern analysis\n",
    "        print(f\"\\nPattern Analysis:\")\n",
    "        print(f\"  Groups in pattern: {compiled_pattern.groups}\")\n",
    "        if hasattr(compiled_pattern, 'groupindex'):\n",
    "            print(f\"  Named groups: {compiled_pattern.groupindex}\")\n",
    "            \n",
    "    except re.error as e:\n",
    "        print(f\"Regex Error: {e}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Debug examples\n",
    "debug_regex(\n",
    "    r'(?P<protocol>https?)://(?P<domain>[^/]+)(?P<path>/.*)?',\n",
    "    \"Visit https://www.example.com/path/to/page\",\n",
    "    \"URL parsing with named groups\"\n",
    ")\n",
    "\n",
    "debug_regex(\n",
    "    r'(\\d{2})/(\\d{2})/(\\d{4})',\n",
    "    \"Today is 12/25/2023 and tomorrow is 12/26/2023\",\n",
    "    \"Date extraction with numbered groups\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Working with Large Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing large text (43,300 characters):\n",
      "\n",
      "Finding emails:\n",
      "  Total matches: 300\n",
      "  Unique matches: 3\n",
      "    1. jane.doe@company.org\n",
      "    2. john@example.com\n",
      "    3. support@help.com\n",
      "\n",
      "Finding phones:\n",
      "  Total matches: 200\n",
      "  Unique matches: 2\n",
      "    1. +1-888-555-1234\n",
      "    2. 800-555-0199\n",
      "\n",
      "Finding urls:\n",
      "  Total matches: 200\n",
      "  Unique matches: 2\n",
      "    1. http://subdomain.test.org,\n",
      "    2. https://www.example.com,\n",
      "\n",
      "Finding dates:\n",
      "  Total matches: 300\n",
      "  Unique matches: 3\n",
      "    1. 01/15/2024\n",
      "    2. 2023-12-25\n",
      "    3. March 10, 2024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Working with Large Texts using re.finditer()\n",
    "\n",
    "def process_large_text():\n",
    "    \"\"\"Demonstrate efficient processing of large texts.\"\"\"\n",
    "    \n",
    "    # Simulate a large text file\n",
    "    large_text = \"\"\"\n",
    "    This is a sample document with multiple email addresses like john@example.com,\n",
    "    jane.doe@company.org, and support@help.com. There are also phone numbers\n",
    "    such as (555) 123-4567, 800-555-0199, and +1-888-555-1234.\n",
    "    \n",
    "    URLs in the text include https://www.example.com, http://subdomain.test.org,\n",
    "    and ftp://files.company.com/documents/.\n",
    "    \n",
    "    Some dates mentioned: 2023-12-25, 01/15/2024, and March 10, 2024.\n",
    "    \"\"\" * 100  # Repeat to simulate larger text\n",
    "    \n",
    "    patterns = {\n",
    "        'email': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
    "        'phone': r'\\+?1?[-.]?\\(?([0-9]{3})\\)?[-.]?([0-9]{3})[-.]?([0-9]{4})',\n",
    "        'url': r'https?://[^\\s]+',\n",
    "        'date': r'\\d{4}-\\d{2}-\\d{2}|\\d{2}/\\d{2}/\\d{4}|\\w+ \\d{1,2}, \\d{4}',\n",
    "    }\n",
    "    \n",
    "    print(f\"Processing large text ({len(large_text):,} characters):\")\n",
    "    print()\n",
    "    \n",
    "    # Use finditer for memory-efficient processing\n",
    "    for pattern_name, pattern in patterns.items():\n",
    "        print(f\"Finding {pattern_name}s:\")\n",
    "        \n",
    "        matches = list(re.finditer(pattern, large_text, re.IGNORECASE))\n",
    "        unique_matches = set(match.group() for match in matches)\n",
    "        \n",
    "        print(f\"  Total matches: {len(matches)}\")\n",
    "        print(f\"  Unique matches: {len(unique_matches)}\")\n",
    "        \n",
    "        # Show first few unique matches\n",
    "        for i, match in enumerate(sorted(unique_matches)[:3]):\n",
    "            print(f\"    {i+1}. {match}\")\n",
    "        \n",
    "        if len(unique_matches) > 3:\n",
    "            print(f\"    ... and {len(unique_matches) - 3} more\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "process_large_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Exercises and Projects\n",
    "\n",
    "Put your advanced regex skills to the test with these challenging exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Analysis Results:\n",
      "error: No matches found\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Build a Log Analyzer\n",
    "\n",
    "class LogAnalyzer:\n",
    "    \"\"\"Analyze log files using advanced regex patterns.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Common log patterns\n",
    "        self.patterns = {\n",
    "            'apache_common': re.compile(\n",
    "                r'^(?P<ip>\\S+) \\S+ (?P<user>\\S+) \\[(?P<timestamp>[^\\]]+)\\] '\n",
    "                r'\"(?P<method>\\w+) (?P<url>\\S+) (?P<protocol>[^\"]+)\" '\n",
    "                r'(?P<status>\\d+) (?P<size>\\d+)$'\n",
    "            ),\n",
    "            'nginx_error': re.compile(\n",
    "                r'^(?P<timestamp>\\d{4}/\\d{2}/\\d{2} \\d{2}:\\d{2}:\\d{2}) '\n",
    "                r'\\[(?P<level>\\w+)\\] (?P<pid>\\d+)#(?P<tid>\\d+): '\n",
    "                r'(?P<message>.*)$'\n",
    "            ),\n",
    "            'python_traceback': re.compile(\n",
    "                r'Traceback \\(most recent call last\\):.*?'\n",
    "                r'(?P<exception>\\w+Error): (?P<message>.*)',\n",
    "                re.DOTALL\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def analyze_log(self, log_content: str, log_type: str = 'apache_common'):\n",
    "        \"\"\"Analyze log content and extract statistics.\"\"\"\n",
    "        if log_type not in self.patterns:\n",
    "            raise ValueError(f\"Unknown log type: {log_type}\")\n",
    "        \n",
    "        pattern = self.patterns[log_type]\n",
    "        matches = list(pattern.finditer(log_content))\n",
    "        \n",
    "        if not matches:\n",
    "            return {\"error\": \"No matches found\"}\n",
    "        \n",
    "        # Extract statistics based on log type\n",
    "        if log_type == 'apache_common':\n",
    "            return self._analyze_apache_logs(matches)\n",
    "        elif log_type == 'nginx_error':\n",
    "            return self._analyze_nginx_errors(matches)\n",
    "        \n",
    "        return {\"matches\": len(matches)}\n",
    "    \n",
    "    def _analyze_apache_logs(self, matches):\n",
    "        \"\"\"Analyze Apache access logs.\"\"\"\n",
    "        stats = {\n",
    "            'total_requests': len(matches),\n",
    "            'unique_ips': set(),\n",
    "            'status_codes': {},\n",
    "            'methods': {},\n",
    "            'top_urls': {},\n",
    "        }\n",
    "        \n",
    "        for match in matches:\n",
    "            data = match.groupdict()\n",
    "            \n",
    "            # Collect statistics\n",
    "            stats['unique_ips'].add(data['ip'])\n",
    "            \n",
    "            status = data['status']\n",
    "            stats['status_codes'][status] = stats['status_codes'].get(status, 0) + 1\n",
    "            \n",
    "            method = data['method']\n",
    "            stats['methods'][method] = stats['methods'].get(method, 0) + 1\n",
    "            \n",
    "            url = data['url']\n",
    "            stats['top_urls'][url] = stats['top_urls'].get(url, 0) + 1\n",
    "        \n",
    "        # Convert set to count\n",
    "        stats['unique_ips'] = len(stats['unique_ips'])\n",
    "        \n",
    "        # Sort top URLs\n",
    "        stats['top_urls'] = dict(sorted(stats['top_urls'].items(), \n",
    "                                      key=lambda x: x[1], reverse=True)[:5])\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def _analyze_nginx_errors(self, matches):\n",
    "        \"\"\"Analyze Nginx error logs.\"\"\"\n",
    "        stats = {\n",
    "            'total_errors': len(matches),\n",
    "            'error_levels': {},\n",
    "            'common_messages': {},\n",
    "        }\n",
    "        \n",
    "        for match in matches:\n",
    "            data = match.groupdict()\n",
    "            \n",
    "            level = data['level']\n",
    "            stats['error_levels'][level] = stats['error_levels'].get(level, 0) + 1\n",
    "            \n",
    "            message = data['message'][:50]  # First 50 chars\n",
    "            stats['common_messages'][message] = stats['common_messages'].get(message, 0) + 1\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# Test the log analyzer\n",
    "sample_apache_log = \"\"\"\n",
    "192.168.1.1 - - [25/Dec/2023:10:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 1234\n",
    "10.0.0.1 - user [25/Dec/2023:10:01:00 +0000] \"POST /api/login HTTP/1.1\" 401 567\n",
    "192.168.1.1 - - [25/Dec/2023:10:02:00 +0000] \"GET /images/logo.png HTTP/1.1\" 404 0\n",
    "203.0.113.1 - - [25/Dec/2023:10:03:00 +0000] \"GET /index.html HTTP/1.1\" 200 1234\n",
    "\"\"\".strip()\n",
    "\n",
    "analyzer = LogAnalyzer()\n",
    "results = analyzer.analyze_log(sample_apache_log, 'apache_common')\n",
    "\n",
    "print(\"Log Analysis Results:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Extraction Results:\n",
      "\n",
      "Financial Data:\n",
      "  currency: ['$2,450,000.00']\n",
      "  percentage: ['15.5%', '3.2%']\n",
      "  stock_symbol: ['MSFT', 'AAPL']\n",
      "\n",
      "Personal Data:\n",
      "  ssn: ['123-45-6789']\n",
      "  credit_card: ['4532-1234-5678-9012']\n",
      "  driver_license: ['A1234567']\n",
      "\n",
      "Technical Data:\n",
      "  ip_address: ['192.168.1.100']\n",
      "  mac_address: ['00:1B:44:11:3A:B7']\n",
      "  version: ['5.7.2', '3.2', '15.5', 'v2.1.3', '192.168.1.100', '000.00']\n",
      "\n",
      "==================================================\n",
      "Cleaned Text (sensitive data redacted):\n",
      "\n",
      "Financial Report Q4 2023:\n",
      "Revenue increased by 15.5% to $2,450,000.00 this quarter.\n",
      "AAPL stock performed well, while MSFT shares declined 3.2%.\n",
      "\n",
      "Contact Information:\n",
      "John Smith: [REDACTED], [REDACTED]\n",
      "SSN: [REDACTED], Driver License: [REDACTED]\n",
      "Credit Card: [REDACTED]\n",
      "\n",
      "Technical Details:\n",
      "Server IP: 192.168.1.100, MAC: 00:1B:44:11:3A:B7\n",
      "Software version: v2.1.3, Database version: 5.7.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Advanced Data Extraction and Cleaning\n",
    "\n",
    "class DataExtractor:\n",
    "    \"\"\"Extract and clean data from unstructured text using advanced regex.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.patterns = {\n",
    "            'financial': {\n",
    "                'currency': re.compile(r'\\$[\\d,]+(?:\\.\\d{2})?|\\d+(?:\\.\\d{2})?\\s*(?:dollars?|USD|\\$)'),\n",
    "                'percentage': re.compile(r'\\d+(?:\\.\\d+)?%'),\n",
    "                'stock_symbol': re.compile(r'\\b[A-Z]{2,5}\\b(?=\\s*(?:stock|shares?|ticker))'),\n",
    "            },\n",
    "            'personal': {\n",
    "                'ssn': re.compile(r'\\b\\d{3}-\\d{2}-\\d{4}\\b'),\n",
    "                'credit_card': re.compile(r'\\b(?:\\d{4}[- ]?){3}\\d{4}\\b'),\n",
    "                'driver_license': re.compile(r'\\b[A-Z]\\d{7,8}\\b'),\n",
    "            },\n",
    "            'technical': {\n",
    "                'ip_address': re.compile(r'\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b'),\n",
    "                'mac_address': re.compile(r'\\b[0-9A-Fa-f]{2}(?:[:-][0-9A-Fa-f]{2}){5}\\b'),\n",
    "                'version': re.compile(r'\\bv?\\d+(?:\\.\\d+){1,3}\\b'),\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def extract_data(self, text: str, category: str = None) -> dict:\n",
    "        \"\"\"Extract data from text, optionally filtering by category.\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        categories = [category] if category else self.patterns.keys()\n",
    "        \n",
    "        for cat in categories:\n",
    "            if cat not in self.patterns:\n",
    "                continue\n",
    "                \n",
    "            results[cat] = {}\n",
    "            \n",
    "            for pattern_name, pattern in self.patterns[cat].items():\n",
    "                matches = pattern.findall(text)\n",
    "                if matches:\n",
    "                    results[cat][pattern_name] = list(set(matches))  # Remove duplicates\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def clean_sensitive_data(self, text: str, replacement: str = \"[REDACTED]\") -> str:\n",
    "        \"\"\"Clean sensitive data from text.\"\"\"\n",
    "        sensitive_patterns = {\n",
    "            **self.patterns['personal'],\n",
    "            'email': re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'),\n",
    "            'phone': re.compile(r'\\b\\(?([0-9]{3})\\)?[-. ]?([0-9]{3})[-. ]?([0-9]{4})\\b'),\n",
    "        }\n",
    "        \n",
    "        cleaned_text = text\n",
    "        \n",
    "        for pattern_name, pattern in sensitive_patterns.items():\n",
    "            cleaned_text = pattern.sub(replacement, cleaned_text)\n",
    "        \n",
    "        return cleaned_text\n",
    "\n",
    "# Test the data extractor\n",
    "sample_text = \"\"\"\n",
    "Financial Report Q4 2023:\n",
    "Revenue increased by 15.5% to $2,450,000.00 this quarter.\n",
    "AAPL stock performed well, while MSFT shares declined 3.2%.\n",
    "\n",
    "Contact Information:\n",
    "John Smith: 555-123-4567, john.smith@company.com\n",
    "SSN: 123-45-6789, Driver License: A1234567\n",
    "Credit Card: 4532-1234-5678-9012\n",
    "\n",
    "Technical Details:\n",
    "Server IP: 192.168.1.100, MAC: 00:1B:44:11:3A:B7\n",
    "Software version: v2.1.3, Database version: 5.7.2\n",
    "\"\"\"\n",
    "\n",
    "extractor = DataExtractor()\n",
    "\n",
    "print(\"Data Extraction Results:\")\n",
    "extracted = extractor.extract_data(sample_text)\n",
    "for category, data in extracted.items():\n",
    "    if data:  # Only show categories with data\n",
    "        print(f\"\\n{category.title()} Data:\")\n",
    "        for pattern_name, matches in data.items():\n",
    "            print(f\"  {pattern_name}: {matches}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Cleaned Text (sensitive data redacted):\")\n",
    "cleaned = extractor.clean_sensitive_data(sample_text)\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've completed this comprehensive advanced regex tutorial. You've learned:\n",
    "\n",
    "### Key Concepts Covered:\n",
    "1. **Lookahead and Lookbehind Assertions** - For context-aware matching\n",
    "2. **Capturing Groups and Backreferences** - For extracting and referencing parts of matches\n",
    "3. **Performance Optimization** - Avoiding catastrophic backtracking and using efficient patterns\n",
    "4. **Conditional Patterns** - Matching different alternatives based on conditions\n",
    "5. **Unicode and International Text** - Working with non-ASCII characters\n",
    "6. **Real-world Applications** - Log parsing, data extraction, and validation\n",
    "7. **Debugging and Testing** - Tools and techniques for regex development\n",
    "8. **Advanced Python Features** - Custom classes, function-based substitutions, and optimization\n",
    "\n",
    "### Best Practices to Remember:\n",
    "- **Compile patterns** when using them repeatedly\n",
    "- **Use specific patterns** instead of overly general ones\n",
    "- **Test thoroughly** with edge cases\n",
    "- **Consider performance** implications of complex patterns\n",
    "- **Document complex patterns** for maintainability\n",
    "- **Use appropriate tools** - sometimes regex isn't the best solution\n",
    "\n",
    "### Next Steps:\n",
    "- Practice with real-world data from your domain\n",
    "- Explore regex in other programming languages\n",
    "- Learn about parsing libraries for complex structured data\n",
    "- Study formal language theory for deeper understanding\n",
    "\n",
    "### Resources for Further Learning:\n",
    "- [Python re module documentation](https://docs.python.org/3/library/re.html)\n",
    "- [RegexOne Interactive Tutorial](https://regexone.com/)\n",
    "- [Regex101 Online Tester](https://regex101.com/)\n",
    "- [Regular-Expressions.info](https://www.regular-expressions.info/)\n",
    "\n",
    "Keep practicing and experimenting with these advanced concepts. Regular expressions are a powerful tool that becomes more valuable as you master their intricacies!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
